# ğŸ§  AI Web Scraper

An intelligent web scraping tool that uses LLMs to extract **custom data** from any website based on user instructions â€” no hardcoded schemas, no manual HTML parsing. Just describe what you want, and get structured JSON/CSV instantly.

---

## ğŸš€ Features

- ğŸ” **Scrape any website** using a simple URL input  
- ğŸ¤– **LLM-powered extraction** â€” extract *any* type of information (products, prices, tables, FAQs, metadata, etc.)  
- ğŸ“¦ **Structured output** in both JSON and CSV  
- ğŸ’¬ **Natural language prompts** â€” just ask what you want  
- ğŸ§  Built-in support for **Gemma**, **LLaMA3**, and **Mistral** via Ollama  
- ğŸ“¥ **Download results** with one click  
- ğŸ§¾ **Chat history** to review previous queries  
- ğŸ§¹ Clean and readable text content powered by BeautifulSoup and custom cleaning

---

## ğŸ—ï¸ Tech Stack

- `Python 3.10+`  
- `Streamlit` â€“ UI  
- `Selenium` â€“ DOM scraping  
- `BeautifulSoup` â€“ HTML parsing  
- `LangChain + Ollama` â€“ LLM chat interface  
- `Pandas` â€“ data tabulation and CSV export  

---

## ğŸ“¦ Project Structure

```
.
â”œâ”€â”€ main.py                         # Streamlit app entry point
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ parser.py              # LLM prompt and logic handler
â”‚   â”‚   â””â”€â”€ scraper.py             # Web scraper using Selenium
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ common.py              # JSON/CSV handlers, content split, cleaning
â”‚   â”œâ”€â”€ Logging/
â”‚   â”‚   â””â”€â”€ logger.py              # Logging configuration
â”œâ”€â”€ output_data/
â”‚   â”œâ”€â”€ output.json                # Extracted structured data
â”‚   â””â”€â”€ output.csv                 # CSV version of the same
```

---

## âš™ï¸ Setup Instructions

1. **Clone the Repository**
   ```bash
   git clone https://github.com/OmRajput17/ai-web-scraper.git
   cd ai-web-scraper
   ```

2. **Install Dependencies**
   Use a virtual environment (recommended):
   ```bash
   python -m venv ai
   source ai/bin/activate   # or ai\Scripts\activate on Windows
   pip install -r requirements.txt
   ```

3. **Run the App**
   ```bash
   streamlit run main.py
   ```

4. **Requirements**
   - [Ollama](https://ollama.com/) must be installed and running
   - Ensure `gemma`, `llama3`, or `mistral` models are available in Ollama
   - `ChromeDriver` must be available in your root folder or PATH

---

## ğŸ§  How to Use

1. Paste the URL of the website you want to scrape.
2. Click **"Scrape Website"**.
3. Enter a **natural language instruction**, like:
   - "Extract all product names and prices"
   - "Get all customer reviews and ratings"
   - "List job postings and locations"
4. View the structured results and download them as `.json` or `.csv`.

---

## âœ… Output Format

Always returns a clean list of dictionaries:

```json
[
  {
    "brand": "GTPLAYER",
    "price": "â‚¹12,999",
    "rating": "4.3",
    "description": "Ergonomic Gaming Chair with Footrest..."
  }
]
```

---

## ğŸ“„ License

This project is open-source and free to use.

---